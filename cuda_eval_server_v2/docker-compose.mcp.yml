version: '3.8'

services:
  # MCP Server only
  mcp-server:
    build:
      context: ../../../
      dockerfile: KernelBench/scripts/cuda_eval_server_v2/Dockerfile.mcp
    image: cuda-eval-mcp-server:latest
    container_name: cuda-eval-mcp-server
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE=0
      - ENABLE_DEVICE_METRICS=false
      - LOG_LEVEL=INFO
      - CUPY_KERNEL_CACHE_DIR=/tmp/cupy_kernel_cache
    volumes:
      - /tmp:/tmp
      - ./logs:/app/logs
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Hybrid mode - Both FastAPI and MCP
  hybrid-server:
    build:
      context: ../../../
      dockerfile: KernelBench/scripts/cuda_eval_server_v2/Dockerfile.mcp
    image: cuda-eval-hybrid-server:latest
    container_name: cuda-eval-hybrid-server
    runtime: nvidia
    command: ["python3", "main.py", "--mode", "both", "--host", "0.0.0.0", "--port", "8000", "--log-level", "info"]
    ports:
      - "8000:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE=0
      - ENABLE_DEVICE_METRICS=false
      - LOG_LEVEL=INFO
      - CUPY_KERNEL_CACHE_DIR=/tmp/cupy_kernel_cache
    volumes:
      - /tmp:/tmp
      - ./logs:/app/logs
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # FastAPI server only (existing functionality)
  fastapi-server:
    build:
      context: ../../../
      dockerfile: KernelBench/scripts/cuda_eval_server_v2/Dockerfile
    image: cuda-eval-fastapi-server:latest
    container_name: cuda-eval-fastapi-server
    runtime: nvidia
    command: ["python3", "main.py", "--mode", "fastapi", "--host", "0.0.0.0", "--port", "8000", "--log-level", "info"]
    ports:
      - "8000:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - GPU_DEVICE=0
      - ENABLE_DEVICE_METRICS=false
      - LOG_LEVEL=INFO
      - CUPY_KERNEL_CACHE_DIR=/tmp/cupy_kernel_cache
    volumes:
      - /tmp:/tmp
      - ./logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
